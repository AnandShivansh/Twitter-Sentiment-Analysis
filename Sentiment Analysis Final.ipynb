{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the keyword for which you want to see the sentiments of the public.\n",
      "Donald trump\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "\n",
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'XXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXxx'\n",
    "\n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "            \n",
    "            \n",
    "    def preprocess(self, text, stem=False):\n",
    "        # Remove link,user and special characters\n",
    "        tokens = []\n",
    "        for token in text.split():\n",
    "            if token not in stop_words:\n",
    "                if stem:\n",
    "                    tokens.append(stemmer.stem(token))\n",
    "                else:\n",
    "                    tokens.append(token)\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        tweet = tweet.lower()\n",
    "        # Replaces URLs with the word URL\n",
    "        tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "        # Replace @handle with the word USER_MENTION\n",
    "        tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "        # Replaces #hashtag with hashtag\n",
    "        tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "        # Remove RT (retweet)\n",
    "        tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "        # Replace 2+ dots with space\n",
    "        tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "        # Strip space, \" and ' from tweet\n",
    "        tweet = tweet.strip(' \"\\'')\n",
    "        # Replace emojis with either EMO_POS or EMO_NEG\n",
    "        # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "        tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "        # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "        tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "        # Love -- <3, :*\n",
    "        tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "        # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "        tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "        # Sad -- :-(, : (, :(, ):, )-:\n",
    "        tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "        # Cry -- :,(, :'(, :\"(\n",
    "        tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "        # Replace multiple spaces with a single space\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "        tweet = self.preprocess(tweet)\n",
    "        return ' '.join(tweet.split()) \n",
    "    \n",
    "\n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "\n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "\n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "\n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = self.clean_tweet(tweet.text) \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['resultant_sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "\n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "\n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "\n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "\n",
    " \n",
    "    # creating object of TwitterClient Class \n",
    "api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "\n",
    "\n",
    "    # printing first 5 positive tweets \n",
    "#     print(\"\\n\\nPositive tweets:\") \n",
    "#     for tweet in tweets[:10]: \n",
    "#         print(\"*\"+tweet['text'])\n",
    "import pandas as pd \n",
    "print(\"Enter the keyword for which you want to see the sentiments of the public.\")\n",
    "a = input()\n",
    "tweets = api.get_tweets(query = a, count = 200) \n",
    "df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>resultant_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER_MENTION kung biglang magsungit man ako, k...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER_MENTION spongebob never made bad track. g...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USER_MENTION USER_MENTION think exact opposite...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER_MENTION years still happening day, please...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER_MENTION you’re bad day, remember. probabl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text resultant_sentiment\n",
       "0  USER_MENTION kung biglang magsungit man ako, k...            negative\n",
       "1  USER_MENTION spongebob never made bad track. g...            positive\n",
       "2  USER_MENTION USER_MENTION think exact opposite...            positive\n",
       "3  USER_MENTION years still happening day, please...            positive\n",
       "4  USER_MENTION you’re bad day, remember. probabl...            negative"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditi/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [_text.split() for _text in df.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = [_text.split() for _text in [\"we are going to love you\"]] \n",
    "test2 = [_text.split() for _text in [\"good boy\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250259</td>\n",
       "      <td>0.363413</td>\n",
       "      <td>0.304923</td>\n",
       "      <td>-0.098786</td>\n",
       "      <td>-0.322563</td>\n",
       "      <td>0.143053</td>\n",
       "      <td>0.154211</td>\n",
       "      <td>-0.067273</td>\n",
       "      <td>-0.165551</td>\n",
       "      <td>0.134352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224850</td>\n",
       "      <td>0.445878</td>\n",
       "      <td>0.219864</td>\n",
       "      <td>0.159322</td>\n",
       "      <td>0.459781</td>\n",
       "      <td>0.132345</td>\n",
       "      <td>-0.072165</td>\n",
       "      <td>-0.022730</td>\n",
       "      <td>-0.336262</td>\n",
       "      <td>-0.288855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.407935</td>\n",
       "      <td>-0.152610</td>\n",
       "      <td>0.065117</td>\n",
       "      <td>-0.036662</td>\n",
       "      <td>0.357301</td>\n",
       "      <td>0.387878</td>\n",
       "      <td>0.467660</td>\n",
       "      <td>0.150157</td>\n",
       "      <td>0.333346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111404</td>\n",
       "      <td>0.158134</td>\n",
       "      <td>-0.013688</td>\n",
       "      <td>-0.527503</td>\n",
       "      <td>0.380493</td>\n",
       "      <td>-0.388031</td>\n",
       "      <td>-0.056256</td>\n",
       "      <td>0.563432</td>\n",
       "      <td>-0.389901</td>\n",
       "      <td>0.403929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283720</td>\n",
       "      <td>0.242255</td>\n",
       "      <td>-0.157147</td>\n",
       "      <td>0.142395</td>\n",
       "      <td>0.036252</td>\n",
       "      <td>0.363503</td>\n",
       "      <td>0.076850</td>\n",
       "      <td>0.163377</td>\n",
       "      <td>-0.388005</td>\n",
       "      <td>0.149404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052186</td>\n",
       "      <td>0.148862</td>\n",
       "      <td>-0.249630</td>\n",
       "      <td>0.378697</td>\n",
       "      <td>0.181724</td>\n",
       "      <td>0.110277</td>\n",
       "      <td>-0.351581</td>\n",
       "      <td>-0.301933</td>\n",
       "      <td>-0.155605</td>\n",
       "      <td>0.210676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202060</td>\n",
       "      <td>0.490750</td>\n",
       "      <td>0.245878</td>\n",
       "      <td>-0.311543</td>\n",
       "      <td>-0.147089</td>\n",
       "      <td>0.208966</td>\n",
       "      <td>0.137801</td>\n",
       "      <td>0.345110</td>\n",
       "      <td>-0.015593</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384091</td>\n",
       "      <td>0.128436</td>\n",
       "      <td>-0.029694</td>\n",
       "      <td>-0.034807</td>\n",
       "      <td>-0.257957</td>\n",
       "      <td>-0.171794</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>-0.226728</td>\n",
       "      <td>-0.406216</td>\n",
       "      <td>0.043717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274666</td>\n",
       "      <td>0.412749</td>\n",
       "      <td>0.202931</td>\n",
       "      <td>-0.089640</td>\n",
       "      <td>-0.031670</td>\n",
       "      <td>0.259341</td>\n",
       "      <td>0.251115</td>\n",
       "      <td>0.353040</td>\n",
       "      <td>0.125677</td>\n",
       "      <td>0.161168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>-0.109795</td>\n",
       "      <td>0.207997</td>\n",
       "      <td>0.072212</td>\n",
       "      <td>-0.025799</td>\n",
       "      <td>-0.193316</td>\n",
       "      <td>-0.228833</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>-0.044962</td>\n",
       "      <td>0.222814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.294585</td>\n",
       "      <td>0.394379</td>\n",
       "      <td>0.091458</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>-0.289807</td>\n",
       "      <td>-0.092539</td>\n",
       "      <td>-0.044057</td>\n",
       "      <td>0.264067</td>\n",
       "      <td>0.430964</td>\n",
       "      <td>-0.067173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254263</td>\n",
       "      <td>0.201133</td>\n",
       "      <td>0.120866</td>\n",
       "      <td>-0.166033</td>\n",
       "      <td>0.087171</td>\n",
       "      <td>-0.281296</td>\n",
       "      <td>0.152616</td>\n",
       "      <td>-0.033951</td>\n",
       "      <td>-0.564000</td>\n",
       "      <td>0.071353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.494898</td>\n",
       "      <td>-0.048262</td>\n",
       "      <td>-0.415276</td>\n",
       "      <td>-0.037659</td>\n",
       "      <td>-0.471465</td>\n",
       "      <td>-0.593650</td>\n",
       "      <td>0.086959</td>\n",
       "      <td>0.130786</td>\n",
       "      <td>0.110508</td>\n",
       "      <td>0.367451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143945</td>\n",
       "      <td>0.374847</td>\n",
       "      <td>0.135156</td>\n",
       "      <td>0.331725</td>\n",
       "      <td>0.133048</td>\n",
       "      <td>0.060897</td>\n",
       "      <td>-0.046874</td>\n",
       "      <td>-0.507817</td>\n",
       "      <td>-0.294147</td>\n",
       "      <td>-0.096055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.062984</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.021747</td>\n",
       "      <td>-0.234296</td>\n",
       "      <td>0.121840</td>\n",
       "      <td>0.071136</td>\n",
       "      <td>-0.005935</td>\n",
       "      <td>0.162295</td>\n",
       "      <td>0.096997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450455</td>\n",
       "      <td>0.269456</td>\n",
       "      <td>0.041603</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>0.116374</td>\n",
       "      <td>-0.168266</td>\n",
       "      <td>0.212704</td>\n",
       "      <td>-0.125080</td>\n",
       "      <td>-0.057838</td>\n",
       "      <td>-0.031910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.429995</td>\n",
       "      <td>-0.029373</td>\n",
       "      <td>-0.002410</td>\n",
       "      <td>-0.380935</td>\n",
       "      <td>-0.318411</td>\n",
       "      <td>-0.773685</td>\n",
       "      <td>0.337890</td>\n",
       "      <td>0.190631</td>\n",
       "      <td>0.722611</td>\n",
       "      <td>0.270579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138991</td>\n",
       "      <td>1.169573</td>\n",
       "      <td>0.041825</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.614721</td>\n",
       "      <td>-0.310854</td>\n",
       "      <td>-0.045122</td>\n",
       "      <td>0.601854</td>\n",
       "      <td>-0.574123</td>\n",
       "      <td>-0.521743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.268219</td>\n",
       "      <td>0.507536</td>\n",
       "      <td>-0.234717</td>\n",
       "      <td>0.372104</td>\n",
       "      <td>0.129520</td>\n",
       "      <td>0.545209</td>\n",
       "      <td>0.241346</td>\n",
       "      <td>0.207221</td>\n",
       "      <td>-0.437464</td>\n",
       "      <td>0.233843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267597</td>\n",
       "      <td>0.075694</td>\n",
       "      <td>0.084324</td>\n",
       "      <td>-0.032847</td>\n",
       "      <td>-0.197155</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>-0.411878</td>\n",
       "      <td>0.040150</td>\n",
       "      <td>-0.339100</td>\n",
       "      <td>0.275788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -0.250259  0.363413  0.304923 -0.098786 -0.322563  0.143053  0.154211   \n",
       "1   0.666645  0.407935 -0.152610  0.065117 -0.036662  0.357301  0.387878   \n",
       "2   0.283720  0.242255 -0.157147  0.142395  0.036252  0.363503  0.076850   \n",
       "3   0.202060  0.490750  0.245878 -0.311543 -0.147089  0.208966  0.137801   \n",
       "4   0.274666  0.412749  0.202931 -0.089640 -0.031670  0.259341  0.251115   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "76  0.294585  0.394379  0.091458  0.025754 -0.289807 -0.092539 -0.044057   \n",
       "77  0.494898 -0.048262 -0.415276 -0.037659 -0.471465 -0.593650  0.086959   \n",
       "78 -0.062984 -0.000565  0.009214  0.021747 -0.234296  0.121840  0.071136   \n",
       "79 -0.429995 -0.029373 -0.002410 -0.380935 -0.318411 -0.773685  0.337890   \n",
       "80  0.268219  0.507536 -0.234717  0.372104  0.129520  0.545209  0.241346   \n",
       "\n",
       "          7         8         9   ...        90        91        92        93  \\\n",
       "0  -0.067273 -0.165551  0.134352  ... -0.224850  0.445878  0.219864  0.159322   \n",
       "1   0.467660  0.150157  0.333346  ... -0.111404  0.158134 -0.013688 -0.527503   \n",
       "2   0.163377 -0.388005  0.149404  ... -0.052186  0.148862 -0.249630  0.378697   \n",
       "3   0.345110 -0.015593  0.077107  ... -0.384091  0.128436 -0.029694 -0.034807   \n",
       "4   0.353040  0.125677  0.161168  ... -0.002296 -0.109795  0.207997  0.072212   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "76  0.264067  0.430964 -0.067173  ... -0.254263  0.201133  0.120866 -0.166033   \n",
       "77  0.130786  0.110508  0.367451  ...  0.143945  0.374847  0.135156  0.331725   \n",
       "78 -0.005935  0.162295  0.096997  ... -0.450455  0.269456  0.041603  0.118159   \n",
       "79  0.190631  0.722611  0.270579  ...  0.138991  1.169573  0.041825  0.013802   \n",
       "80  0.207221 -0.437464  0.233843  ... -0.267597  0.075694  0.084324 -0.032847   \n",
       "\n",
       "          94        95        96        97        98        99  \n",
       "0   0.459781  0.132345 -0.072165 -0.022730 -0.336262 -0.288855  \n",
       "1   0.380493 -0.388031 -0.056256  0.563432 -0.389901  0.403929  \n",
       "2   0.181724  0.110277 -0.351581 -0.301933 -0.155605  0.210676  \n",
       "3  -0.257957 -0.171794  0.006300 -0.226728 -0.406216  0.043717  \n",
       "4  -0.025799 -0.193316 -0.228833  0.072230 -0.044962  0.222814  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "76  0.087171 -0.281296  0.152616 -0.033951 -0.564000  0.071353  \n",
       "77  0.133048  0.060897 -0.046874 -0.507817 -0.294147 -0.096055  \n",
       "78  0.116374 -0.168266  0.212704 -0.125080 -0.057838 -0.031910  \n",
       "79  0.614721 -0.310854 -0.045122  0.601854 -0.574123 -0.521743  \n",
       "80 -0.197155 -0.014839 -0.411878  0.040150 -0.339100  0.275788  \n",
       "\n",
       "[81 rows x 100 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector\n",
    "    \n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# get document level embeddings\n",
    "w2v_feature_array = averaged_word_vectorizer(corpus=documents, model=model,\n",
    "                                             num_features=100)\n",
    "pd.DataFrame(w2v_feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict(w2v_feature_array) # predicting on the validation set\n",
    "# prediction = loaded_model.predict(X_tf1) # predicting on the validation set\n",
    "\n",
    "# prediction_int = prediction>= 0.3 # if prediction is greater than or equal to 0.3 than 1 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction # 0 means negative and 1 means positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
